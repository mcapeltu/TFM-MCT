{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "from numba import cuda, float32, float64\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import random\n",
    "from numba import cuda\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(file):\n",
    "    file=open(file, 'r')\n",
    "    reader=csv.reader(file)\n",
    "    data= []\n",
    "    for line in reader:\n",
    "        data.append(line)\n",
    "    data=np.array(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computes wT*x[i] ( the predicted value for datum)\n",
    "def H(x,w,i):\n",
    "    sum=0\n",
    "    for j in range(len(x[0])):\n",
    "        sum+=x[i][j]*w[j]\n",
    "    return sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(x, weights):\n",
    "    weights2=weights[n_inputs*n_hidden:]\n",
    "    z3=0\n",
    "    #Pass data from the initial layer to the hidden neurons\n",
    "    for j in range(0,n_hidden-1):\n",
    "        weights1=weights[n_inputs*j:n_inputs*(j+1)]\n",
    "        result=0\n",
    "        for k in range(0,n_inputs):\n",
    "            result+=(x[k]*weights1[k])\n",
    "            #result+=0.1\n",
    "        #Activation function ReLu\n",
    "        #result=max(0, result)\n",
    "        #We can add what each hidden neuron contributes to the output layer\n",
    "        z3+=result*weights2[j]\n",
    "    #We add the bias\n",
    "    z3+=weights2[n_hidden-1]\n",
    "    return z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for calculating the error\n",
    "def forward_propagation_Error(x,y,w):\n",
    "    E=0\n",
    "    for i in range(0, len(x)):\n",
    "        wx=0\n",
    "        wx=forward_prop(x[i], w)\n",
    "        E+=((wx-y[i][0])**2)\n",
    "    E=E/len(x)\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self, position, initial_fitness):\n",
    "         # particles position\n",
    "        self.particle_position = position\n",
    "        #initial value of the particle (infinity or minus infinity,\n",
    "        #depending on whether we want to maximize or minimize)\n",
    "        self.fitness_particle_position = initial_fitness\n",
    "        # best position of the particle\n",
    "        self.local_best_particle_position = []  \n",
    "        #best initial value of the particle (infinity or minus infinity, \n",
    "        #depending on whether we want to maximize or minimize)\n",
    "        self.fitness_local_best_particle_position = initial_fitness  \n",
    "        # particle's velocity\n",
    "        self.particle_velocity = []  \n",
    "        for i in range(0,num_dimensions):\n",
    "            #we generate the initial velocity randomly\n",
    "            self.particle_velocity.append(random.uniform(-vMax, vMax))  \n",
    " \n",
    "    def evaluate(self, x, y, mm):\n",
    "        self.fitness_particle_position = forward_propagation_Error(x, y, self.particle_position)\n",
    "        if mm == -1:\n",
    "            if self.fitness_particle_position < self.fitness_local_best_particle_position:\n",
    "                # We update the best local position\n",
    "                self.local_best_particle_position = self.particle_position  \n",
    "                # We update the best local value \n",
    "                self.fitness_local_best_particle_position = self.fitness_particle_position          \n",
    "        if mm == 1:\n",
    "            if self.fitness_particle_position > self.fitness_local_best_particle_position:\n",
    "                 # We update the best local position\n",
    "                self.local_best_particle_position = self.particle_position  \n",
    "                # We update the best local value \n",
    "                self.fitness_local_best_particle_position = self.fitness_particle_position   \n",
    "    def update_velocity(self, global_best_particle_position, w, Vmax, c1=2.8, c2=1.3):\n",
    "        for i in range(0,num_dimensions):\n",
    "            r1 = random.random()\n",
    "            r2 = random.random()\n",
    "            #We calculate the new velocity\n",
    "            self.particle_velocity[i] = w * self.particle_velocity[i] + c1 * r1 * (self.local_best_particle_position[i] - self.particle_position[i]) + c2 * r2 * (global_best_particle_position[i] - self.particle_position[i])\n",
    "            \n",
    "            #We limit the maxmum velocity\n",
    "            if(self.particle_velocity[i]>Vmax):\n",
    "                self.particle_velocity[i]=Vmax\n",
    "            if(self.particle_velocity[i]<-Vmax):\n",
    "                self.particle_velocity[i]=-Vmax\n",
    " \n",
    "    def update_position(self, bounds):\n",
    "        for i in range(0,num_dimensions):\n",
    "            self.particle_position[i] = self.particle_position[i] + self.particle_velocity[i]\n",
    " \n",
    "            #if it reaches the edges, it stays within, it does not exceed the limits\n",
    "            if self.particle_position[i] > bounds[1]:\n",
    "                self.particle_position[i] = bounds[1]\n",
    "            if self.particle_position[i] < bounds[0]:\n",
    "                self.particle_position[i] = bounds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector x_train  [[3.30000000e+01 2.68000000e+01 4.18325768e+01 ... 5.98324000e+01\n",
      "  2.68650000e+00 5.28332422e+03]\n",
      " [2.72000000e+01 1.78000000e+01 6.27743187e+01 ... 5.09312000e+01\n",
      "  4.12500000e-01 4.47110059e+03]\n",
      " [2.89000000e+01 2.08000000e+01 5.82140617e+01 ... 2.87000000e+01\n",
      "  6.23300000e-01 4.76898047e+03]\n",
      " ...\n",
      " [2.59000000e+01 2.44000000e+01 7.02739105e+01 ... 5.09312000e+01\n",
      "  4.12500000e-01 5.60439941e+03]\n",
      " [2.88000000e+01 2.41000000e+01 3.74082756e+01 ... 5.46384000e+01\n",
      "  1.45700000e-01 4.45902344e+03]\n",
      " [2.68000000e+01 2.34000000e+01 4.73865318e+01 ... 5.98324000e+01\n",
      "  2.68650000e+00 5.25598779e+03]]\n",
      "vector y_train  [35.2 24.5 29.4 ... 28.5 28.4 27.6]\n"
     ]
    }
   ],
   "source": [
    "#PS0 parameters\n",
    "num_iters=10\n",
    "num_particles=46\n",
    "c1=2.8\n",
    "c2=1.3\n",
    "factor=10\n",
    "Fi=c1+c2\n",
    "Xi=2/(abs(2-Fi-math.sqrt(abs(Fi**2-4*Fi))))\n",
    "data=readData('Bias_correction_ucl.csv')\n",
    "#print('Data prior removing',data)\n",
    "#We remove the first row of names and the last column\n",
    "data=data[1:,2:24]\n",
    "#print('Data after removing',data)\n",
    "# We preprocess the data\n",
    "datosPandas=pd.DataFrame(data)\n",
    "#We refill the missing data with the averagge\n",
    "datosPandas.replace('?',np.NaN,inplace=True)\n",
    "imp=SimpleImputer(missing_values=np.NaN)\n",
    "datos=imp.fit_transform(datosPandas)\n",
    "#print('Datos after pre-processing',datos)\n",
    "# Shuffle the data list above\n",
    "np.random.shuffle(datos)\n",
    "#Percentage of training (in this sample, 50%) and percentage of testing (25%)\n",
    "p_train = 0.7\n",
    "#Number of elements in the training and test datasets\n",
    "len_train=int((len(datos))*p_train)\n",
    "datos_train=datos[:len_train,:]\n",
    "datos_test=datos[(len_train):,:]\n",
    "#We separate the data \"x\" from the \"y\" (the data \"y\" is in the last column)\n",
    "num_atrib=int(len(datos[0]))-1\n",
    "x_train=datos_train[:,:num_atrib]\n",
    "y_train=datos_train[:,num_atrib]\n",
    "x_test=datos_test[:,:num_atrib]\n",
    "y_test=datos_test[:,num_atrib]\n",
    "print('vector x_train ',x_train)\n",
    "print('vector y_train ',y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector x_train scaled  [[0.74137931 0.83333333 0.28367234 ... 0.23735354 0.50947891 0.56400165]\n",
      " [0.40804598 0.34946237 0.55323478 ... 0.19283975 0.06181467 0.06492858]\n",
      " [0.50574713 0.51075269 0.49453507 ... 0.08166429 0.10331319 0.2479617 ]\n",
      " ...\n",
      " [0.33333333 0.70430108 0.64976964 ... 0.19283975 0.06181467 0.76128719]\n",
      " [0.5        0.68817204 0.22672266 ... 0.21137899 0.00929189 0.05750774]\n",
      " [0.38505747 0.65053763 0.35516294 ... 0.23735354 0.50947891 0.5472047 ]]\n",
      "vector y_train scaled [[0.82790698]\n",
      " [0.33023256]\n",
      " [0.55813953]\n",
      " ...\n",
      " [0.51627907]\n",
      " [0.51162791]\n",
      " [0.4744186 ]]\n"
     ]
    }
   ],
   "source": [
    "#Data re-scaling\n",
    "y_train=np.reshape(y_train, (-1,1))\n",
    "y_test=np.reshape(y_test, (-1,1))\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "#\n",
    "scaler_x.fit(x_train)\n",
    "x_train=scaler_x.transform(x_train)\n",
    "x_test=scaler_x.transform(x_test)\n",
    "#\n",
    "scaler_y.fit(y_train)\n",
    "y_train=scaler_y.transform(y_train)\n",
    "y_test=scaler_y.transform(y_test)\n",
    "print('vector x_train scaled ',x_train)\n",
    "print('vector y_train scaled',y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network parameters (as function of the input)\n",
    "n_inputs=x_train[0].size\n",
    "n_hidden=math.floor(len(x_train)/(factor*(n_inputs+1)))+1\n",
    "#We calculate the number of weights necessary to carry out the computation\n",
    "num_weights=(n_inputs*n_hidden)+n_hidden\n",
    "bound0=float(max(y_train))#upper limit\n",
    "bound1=-bound0 #lower limit\n",
    "vMax=bound0*0.6\n",
    "weights=[]\n",
    "for i in range(0,num_particles):\n",
    "        for j in range(0, num_weights):\n",
    "            weights.append(random.uniform(-1, 1))\n",
    "#print('total number of weights ', len(weights))\n",
    "#print('Initial weights values', weights )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network:\n",
    "    # the parameters are the data, the number of neurons of the input layer, \n",
    "    # the number of neurons of the hidden layer and \n",
    "    # the number of neurons of the output layer\n",
    "    def __init__(self, x, y, n_inputs, n_hidden, weights, num_weights):\n",
    "        self.input=x\n",
    "        self.y=y\n",
    "        \n",
    "        self.weights=weights\n",
    "        self.num_weights=num_weights\n",
    "        \n",
    "    def train_PSO(self):\n",
    "        best_position, fitness=PSO_Neural_Network(self.input, self.y,self.weights, self.num_weights,[bound1,bound0], -1, num_particles, 100, 0.9, 0.1, vMax)\n",
    "        self.weights=best_position\n",
    "        return fitness\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        return forward_prop(x_test, self.weights)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PSO parallel\n",
    "@cuda.jit\n",
    "#def PSO_GPU(x, y):\n",
    "def PSO_GPU(x, y, particle_positions, particle_velocity, personal_best_particle_position,fitness_personal_best_particle_position, local_best_particle_position, fitness_local_best_particle_position,pool, c1, c2, Vmax, bound0, bound1):\n",
    "  \n",
    "    particle= cuda.blockIdx.x #We found the particle that corresponds to the block where the thread is\n",
    "    nx=cuda.threadIdx.x #Finds the neurons of the hidden layer that this thread is going to calculate \n",
    "    #in this thread. Thread '0' does the rest of the particle calculations\n",
    "   \n",
    "    #We initialize the vectors in a shared-memory array (common to the block == to the particle)\n",
    "    z2=cuda.shared.array(shape=n_hidden, dtype=float32)\n",
    "\n",
    "    for iters in range(0, num_iters):\n",
    "        #We take particle's position corresponding to the thread\n",
    "        position=particle_positions[num_weights*particle: num_weights*(particle+1)]\n",
    "\n",
    "        #We do forward propagation\n",
    "        fitness_position=0\n",
    "        weights2=position[n_inputs*n_hidden:]\n",
    "        for i in range(0, len(x)):\n",
    "            j=nx\n",
    "            while(j<n_hidden):\n",
    "                #Pass from the init layer to the hidden layer\n",
    "                hidden_result=0\n",
    "                weights1=position[n_inputs*j:n_inputs*(j+1)]\n",
    "                for k in range(0,n_inputs-1):\n",
    "                    hidden_result+=(x[i][k]*weights1[k])\n",
    "                hidden_result+=weights1[n_inputs-1] #We add the bias\n",
    "                #Function ReLu (activation of)\n",
    "                hidden_result=max(0, hidden_result)\n",
    "                #We save the value in the vector z2, to add it when the total value \n",
    "                #is calculated in the output layer\n",
    "                z2[j]=hidden_result*weights2[j]\n",
    "                j=j+threadsperblock\n",
    "   \n",
    "            # Thread synchronization\n",
    "            cuda.syncthreads()\n",
    "           \n",
    "            #Thread '0' gathers the results of other threads\n",
    "            if(nx==0):\n",
    "                result=0\n",
    "                for h in range (0, n_hidden):\n",
    "                    result+=z2[h]\n",
    "                fitness_position+=float((y[i][0]-result)**2)\n",
    "            # Thread synchronization\n",
    "            cuda.syncthreads()\n",
    "            \n",
    "        if(nx==0):\n",
    "            #We update the best personal position\n",
    "            fitness_position=fitness_position/len(x)\n",
    "            if fitness_position < fitness_personal_best_particle_position[particle]:\n",
    "                for i in range(0, num_weights):\n",
    "                    personal_best_particle_position[(num_weights*particle)+i] = particle_positions[num_weights*particle+i]  # we update the best personal position\n",
    "                # we update the best personal value\n",
    "                fitness_personal_best_particle_position[particle] = fitness_position \n",
    "       \n",
    "        # We synchronize the threads\n",
    "        cuda.syncthreads()\n",
    "       \n",
    "        if(nx==0):\n",
    "            #Best local position updating\n",
    "            if fitness_personal_best_particle_position[particle]< fitness_local_best_particle_position[particle]:\n",
    "                for i in range(0, num_weights):\n",
    "                    local_best_particle_position[num_weights*particle+i] = personal_best_particle_position[(num_weights*particle)+i]\n",
    "                fitness_local_best_particle_position[particle] = fitness_personal_best_particle_position[particle]\n",
    "           \n",
    "            if fitness_personal_best_particle_position[int(math.fmod((num_particles+particle-1), num_particles))] < fitness_local_best_particle_position[particle]:\n",
    "                for i in range(0, num_weights):\n",
    "                    local_best_particle_position[num_weights*(particle)+i] = particle_positions[num_weights*(int(math.fmod((num_particles+particle-1), num_particles)))+i]\n",
    "                fitness_local_best_particle_position[particle] = fitness_personal_best_particle_position[int(math.fmod((num_particles+particle-1), num_particles))]\n",
    "           \n",
    "               \n",
    "            if fitness_personal_best_particle_position[int(math.fmod((num_particles+particle+1), num_particles))] < fitness_local_best_particle_position[particle]:\n",
    "                for i in range(0, num_weights):\n",
    "                    local_best_particle_position[num_weights*(particle)+i] = particle_positions[num_weights*(int(math.fmod((num_particles+particle+1), num_particles)))+i]\n",
    "                fitness_local_best_particle_position[particle] = fitness_personal_best_particle_position[int(math.fmod((num_particles+particle+1), num_particles))]\n",
    "           \n",
    "        # Thread synchronization\n",
    "        cuda.syncthreads()\n",
    "        \n",
    "        #We choose numbers from the random numbers repository\n",
    "        r1=pool[2*num_weights*num_particles+particle+iters]\n",
    "        r2=pool[2*num_weights*num_particles-particle-iters]\n",
    "       \n",
    "        i=nx\n",
    "        #We update each particle's velocity\n",
    "        while i<num_weights:\n",
    "            #We calculate the new velocity\n",
    "            particle_velocity[num_weights*particle+i] = Xi*( particle_velocity[num_weights*particle+i] + c1 * r1 * (personal_best_particle_position[num_weights*particle+i] - particle_positions[num_weights*particle+i]) + c2 * r2 * (local_best_particle_position[num_weights*particle+i] - particle_positions[num_weights*particle+i]))\n",
    "            #We limit speed to maximum speed\n",
    "            if particle_velocity[num_weights*particle+i]>Vmax :\n",
    "                particle_velocity[num_weights*particle+i]=Vmax\n",
    "            if particle_velocity[num_weights*particle+i]<(Vmax*(-1)):\n",
    "                particle_velocity[num_weights*particle+i]=(Vmax*(-1))\n",
    "            i+=threadsperblock\n",
    "       \n",
    "        # Wait until all threads finish computing\n",
    "        cuda.syncthreads()      \n",
    "        i=nx\n",
    "        #We update each particle's position\n",
    "        while i<num_weights:\n",
    "            particle_positions[num_weights*particle+i] = particle_positions[num_weights*particle+i] + particle_velocity[num_weights*particle+i]\n",
    "            #if it reaches and edge, it stays in there, it does not trespasses it\n",
    "            if particle_positions[num_weights*particle+i] > bound0:\n",
    "                particle_positions[num_weights*particle+i] = bound0\n",
    "            if particle_positions[num_weights*particle+i] < bound1:\n",
    "                particle_positions[num_weights*particle+i] = bound1\n",
    "            i+=threadsperblock\n",
    "           \n",
    "        # Wait until all threads finish computing\n",
    "        cuda.syncthreads()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coresPerSM():\n",
    "    cc_cores_per_SM_dict = {\n",
    "    (2,0) : 32,\n",
    "    (2,1) : 48,\n",
    "    (3,0) : 192,\n",
    "    (3,5) : 192,\n",
    "    (3,7) : 192,\n",
    "    (5,0) : 128,\n",
    "    (5,2) : 128,\n",
    "    (6,0) : 64,\n",
    "    (6,1) : 128,\n",
    "    (7,0) : 64,\n",
    "    (7,5) : 64,\n",
    "    (8,0) : 64,\n",
    "    (8,6) : 128\n",
    "    }\n",
    "    # the above dictionary should result in a value of \"None\" if a cc match \n",
    "    # is not found.  The dictionary needs to be extended as new devices become\n",
    "    # available, and currently does not account for all Jetson devices\n",
    "    device = cuda.get_current_device()\n",
    "    #my_cc = getattr(device, 'COMPUTE_CAPABILITY')\n",
    "    my_cc=(6,1)\n",
    "    cores_per_sm = cc_cores_per_SM_dict.get(my_cc)\n",
    "    return cores_per_sm\n",
    "#device = cuda.get_current_device()\n",
    "threadsperblock =  coresPerSM()\n",
    "blockspergrid=num_particles\n",
    "#print('device, num weights, threads per block, blocks, c1, c2, vMax, bound0, bound1 ->',getattr(device, 'MULTIPROCESSOR_COUNT'),num_weights,threadsperblock,blockspergrid,c1, c2, vMax, bound0, bound1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded in GPU correctly!\n"
     ]
    }
   ],
   "source": [
    "#We generate one pool of random numbers and initial data\n",
    "pool=[]\n",
    "fitness_personal_best_particle_position=[]\n",
    "fitness_local_best_particle_position=[]\n",
    "for i in range(0,num_particles):\n",
    "        for j in range(0, num_weights*3):\n",
    "            pool.append(random.uniform(bound1, bound0))\n",
    "        fitness_local_best_particle_position.append(float(\"inf\"))\n",
    "        fitness_personal_best_particle_position.append(float(\"inf\"))\n",
    "#We load data to the gpu\n",
    "x_global_mem=cuda.to_device(np.ascontiguousarray(x_train))\n",
    "y_global_mem=cuda.to_device(np.ascontiguousarray(y_train))\n",
    "fitness_personal_best_particle_position_global_mem=cuda.to_device(np.asarray(fitness_personal_best_particle_position))\n",
    "personal_best_particle_position=cuda.to_device(np.zeros(num_weights*num_particles))\n",
    "local_best_particle_position=cuda.to_device(np.zeros(num_weights*num_particles))\n",
    "fitness_local_best_particle_position_global_mem=cuda.to_device(np.ascontiguousarray(fitness_local_best_particle_position))\n",
    "pool_global_mem=cuda.to_device(np.ascontiguousarray(pool))\n",
    "\n",
    "#We initiate positions and velocities of particles by taking data from the pool of random numbers\n",
    "particles_positions=pool_global_mem[0:num_weights*num_particles]\n",
    "particles_velocity=pool_global_mem[num_weights*num_particles:2*num_weights*num_particles]\n",
    "print(\"Data loaded in GPU correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time(s):  0.9615638256072998\n"
     ]
    }
   ],
   "source": [
    "#And now it's time to launch the computation in parallel!!!!\n",
    "start = time.time()\n",
    "cuda.profile_start()\n",
    "\n",
    "PSO_GPU[blockspergrid, threadsperblock](x_global_mem, y_global_mem,particles_positions, particles_velocity, personal_best_particle_position,fitness_personal_best_particle_position_global_mem, local_best_particle_position,fitness_local_best_particle_position_global_mem, pool_global_mem,c1, c2, vMax, bound0, bound1)\n",
    "\n",
    "local_best_particle_position_host=local_best_particle_position.copy_to_host()\n",
    "fitness_local_best_particle_position=fitness_local_best_particle_position_global_mem.copy_to_host()\n",
    "cuda.profile_stop()\n",
    "end = time.time()\n",
    "time=end - start\n",
    "print(\"Execution time(s): \", time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations of PSO = 10\n",
      "Running time(s):  0.9615638256072998\n",
      "Ein: 0.12252526810069354\n",
      "Eout: 164.83082886755884\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "global_best_particle_position=[]\n",
    "fitness_global_best_particle_position=float(\"inf\")\n",
    "for i in range(0, num_particles):\n",
    "    if(fitness_local_best_particle_position[i]<fitness_global_best_particle_position):\n",
    "        global_best_particle_position=local_best_particle_position_host[num_weights*i:num_weights*(i+1)]\n",
    "        fitness_global_best_particle_position=fitness_local_best_particle_position[i]\n",
    "\n",
    "#We calculate the transfer time between the host (CPU) and the device (GPU), and we remove it from the calculation\n",
    "start2 = time.time()\n",
    "local_best_particle_position_host=local_best_particle_position.copy_to_host()\n",
    "fitness_local_best_particle_position=fitness_local_best_particle_position_global_mem.copy_to_host()\n",
    "end2 = time.time()\n",
    "time_corr=end - start -(end2-start2)\n",
    "#Error calculation\n",
    "Eout=0\n",
    "Error_Cero=0\n",
    "prediction=np.zeros(len(x_test))\n",
    "for i in range(0, len(x_test)):\n",
    "        prediction[i]=forward_prop(x_test[i], global_best_particle_position)\n",
    "        # mean standard error (MSE), for regression problems\n",
    "        Eout+=float((y_test[i][0]-prediction[i]))**2\n",
    "Eout=Eout/len(x_test)\n",
    "#results\n",
    "print(\"Number of iterations of PSO =\", num_iters)\n",
    "print(\"Running time(s): \", time_corr)\n",
    "print('Ein:', fitness_global_best_particle_position)\n",
    "print('Eout:', Eout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
